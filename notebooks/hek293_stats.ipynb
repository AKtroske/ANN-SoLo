{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEK293 identification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "src_dir = os.path.abspath('../src')\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import pyteomics.auxiliary\n",
    "import tqdm\n",
    "\n",
    "from ann_solo import reader, spectrum, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tqdm.tqdm = tqdm.tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_time_from_log(filename):\n",
    "    with open(filename, 'r') as f_in:\n",
    "        for line in f_in:\n",
    "            if 'user' in line:\n",
    "                # user time\n",
    "                usertime = line.split()[1]\n",
    "                minutes = int(usertime[:usertime.find('m')])\n",
    "                seconds = float(usertime[usertime.find('m') + 1: usertime.rfind('s')])\n",
    "                usertime = minutes * 60 + seconds\n",
    "                # sys time\n",
    "                line = next(f_in)\n",
    "                systime = line.split()[1]\n",
    "                minutes = int(systime[:systime.find('m')])\n",
    "                seconds = float(systime[systime.find('m') + 1: systime.rfind('s')])\n",
    "                systime = minutes * 60 + seconds\n",
    "                \n",
    "                return usertime + systime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_spectrast_psms(filename):\n",
    "    psms = pd.read_csv(filename, sep='\\t', header=0)\n",
    "    psms['sequence'] = psms['ID'].str.split('/').str[0]\n",
    "    psms['PSM_ID'] = psms['### Query']\n",
    "    psms['search_engine_score'] = pd.to_numeric(psms['Dot'])\n",
    "    psms['charge'] = pd.to_numeric(psms['ID'].str.split('/').str[1])\n",
    "    psms['mass_diff'] = pd.to_numeric(psms['MzDiff'])\n",
    "    psms['is_decoy'] = psms['Proteins'].str.contains('DECOY_')\n",
    "        \n",
    "    return psms[['sequence', 'PSM_ID', 'search_engine_score', 'charge',\n",
    "                 'mass_diff', 'is_decoy']].set_index('PSM_ID')\n",
    "\n",
    "\n",
    "def _get_bin(psm, tol_mass):\n",
    "    return int(psm['mass_diff'] // tol_mass)\n",
    "\n",
    "\n",
    "def _filter_fdr(psms, fdr):\n",
    "    return pyteomics.auxiliary.filter(\n",
    "        psms, fdr=fdr, key=lambda x: x.search_engine_score, reverse=True,\n",
    "        is_decoy=lambda x: x.is_decoy, remove_decoy=True, formula=1,\n",
    "        correction=0, full_output=True)\n",
    "\n",
    "\n",
    "def filter_group_fdr_spectrast(psms, fdr, tol_mass, min_group_size):\n",
    "    psms['mass_bin'] = psms.apply(_get_bin, axis=1, args=(tol_mass,))\n",
    "    mass_bins = psms.groupby('mass_bin').indices\n",
    "    \n",
    "    groups_common, groups_uncommon = [], []\n",
    "    for _, group in mass_bins.items():\n",
    "        if len(group) >= min_group_size:\n",
    "            groups_common.append(psms.iloc[group])\n",
    "        else:\n",
    "            groups_uncommon.append(psms.iloc[group])\n",
    "    groups_uncommon = pd.concat(groups_uncommon)\n",
    "    \n",
    "    # calculate the FDR combined for all uncommon mass bins\n",
    "    # and separately for each common mass bin    \n",
    "    return pd.concat([_filter_fdr(groups_uncommon, fdr),\n",
    "                      *[_filter_fdr(group, fdr) for group in groups_common]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_fdr = 0.01\n",
    "tol_mass = 0.1\n",
    "min_group_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hek293_dir = '../data/processed/hek293'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_stats = os.path.join(hek293_dir, 'stats.txt')\n",
    "filename_summary = os.path.join(hek293_dir, 'summary.txt')\n",
    "if os.path.isfile(filename_stats) and os.path.isfile(filename_summary):\n",
    "    stats = pd.read_csv(filename_stats, sep='\\t')\n",
    "    summary = pd.read_csv(filename_summary, sep='\\t', index_col=[0, 1])\n",
    "else:\n",
    "    num_ids = []\n",
    "    runtimes = []\n",
    "    psms = collections.defaultdict(list)\n",
    "    total = 24 * 2 * 4    # 24 raw files * 2 (IDs & log) * 4 (search engine combos)\n",
    "    with tqdm.tqdm(desc='Files processed', unit='files', total=total) as pbar:\n",
    "        for search_engine in ('ann-solo', 'spectrast'):\n",
    "            for search_mode in ('oms', 'std'):\n",
    "                for filename in os.listdir(\n",
    "                        os.path.join(hek293_dir, search_engine, search_mode)):\n",
    "                    filename_full = os.path.join(hek293_dir, search_engine,\n",
    "                                                 search_mode, filename)\n",
    "                    if filename.endswith('.log'):\n",
    "                        runtimes.append((\n",
    "                            search_engine, search_mode,\n",
    "                            os.path.splitext(filename)[0],\n",
    "                            extract_time_from_log(filename_full)))\n",
    "                        pbar.update(1)\n",
    "                    else:\n",
    "                        if filename.endswith('.mztab'):\n",
    "                            file_psms = reader.read_mztab_psms(filename_full)\n",
    "                            pbar.update(1)\n",
    "                        elif filename.endswith('.txt'):\n",
    "                            file_psms = filter_group_fdr_spectrast(\n",
    "                                read_spectrast_psms(filename_full),\n",
    "                                max_fdr, tol_mass, min_group_size)\n",
    "                            pbar.update(1)\n",
    "                        psms[(search_engine, search_mode)].append(file_psms)\n",
    "                        num_ids.append((search_engine, search_mode,\n",
    "                                        os.path.splitext(filename)[0],\n",
    "                                        len(file_psms)))\n",
    "\n",
    "    num_ids_df = pd.DataFrame.from_records(\n",
    "        num_ids, columns=['search_engine', 'search_mode', 'filename', 'psms'])\n",
    "    time_df = pd.DataFrame.from_records(\n",
    "        runtimes, columns=['search_engine', 'search_mode', 'filename', 'time'])\n",
    "    stats = (pd.merge(num_ids_df, time_df,\n",
    "                     on=['search_engine', 'search_mode', 'filename'])\n",
    "             .sort_values(['search_engine', 'search_mode', 'filename'])\n",
    "             .reset_index(drop=True))\n",
    "    \n",
    "    summary = (stats.groupby(['search_engine', 'search_mode'])\n",
    "               .agg({'psms': 'sum', 'time': 'mean'}))\n",
    "    summary['time'] = summary['time'] / 60\n",
    "\n",
    "    psms_df = []\n",
    "    for (search_engine, search_mode), psm_list in psms.items():\n",
    "        num_peptides = len(pd.concat(psm_list)['sequence'].unique())\n",
    "        psms_df.append((search_engine, search_mode, num_peptides))\n",
    "    psms_df = pd.DataFrame.from_records(\n",
    "        psms_df, index=['search_engine', 'search_mode'],\n",
    "        columns=['search_engine', 'search_mode', 'peptides'])\n",
    "    summary = summary.join(psms_df)\n",
    "    \n",
    "    stats.to_csv(filename_stats, sep='\\t', index=False)\n",
    "    summary.to_csv(filename_summary, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
